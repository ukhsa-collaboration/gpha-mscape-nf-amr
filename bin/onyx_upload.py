#!/usr/bin/env python3

"""Script to upload data generated by gpha-mscape-nf-amr pipeline. Three possible outputs:
- AMR analysis was not performed on sample.
- No AMR annotations were found for sample.
- AMR annotations were found for sample.
"""

import argparse
import logging
import sys
from importlib import resources
from pathlib import Path
import os
from onyx import OnyxClient, OnyxConfig, OnyxEnv
from onyx_analysis_helper import onyx_analysis_helper_functions as oa

def get_args():
    """Get command line arguments"""
    parser = argparse.ArgumentParser(
        prog="AMR pipeline info Onyx upload",
        description="""Wrapper used to process AMR pipeline outputs. 
        Results are returned in a json format.
        """,
    )
    parser.add_argument("--input", "-i", type=str, required=True, help="Sample ID")
    parser.add_argument(
        "--tsv",
        "-t",
        type=str,
        required=False,
        help="Path to AMR results TSV output file, if available."
    )
    parser.add_argument(
        "--output", "-o", type=str, required=True, help="Folder to save logs to."
    )
    parser.add_argument(
        "--pipeline_status",
        "-p",
        type=str, choices=["Failed","Annotated","None"],
        required=True,
        help="Pipeline Status. Choices: 'Failed', 'Annotated', 'None'"
    )
    parser.add_argument(
        "--server",
        "-s",
        type=str,
        required=True,
        choices=["mscape", "synthscape"],
        help="Specify server code is being run on",
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--no-onyx",
        required=False,
        action="store_true",
        help="Use this option to only write results to file",
    )
    group.add_argument(
        "--store-onyx",
        required=False,
        action="store_true",
        help="Use this option to store results as an onyx analysis object for later upload",
    )
    group.add_argument(
        "--test-onyx",
        required=False,
        action="store_true",
        help="Use this option to do a test upload and check for errors before attempting an upload to onyx",
    )
    group.add_argument(
        "--prod-onyx",
        required=False,
        action="store_true",
        help="Use this option to upload results to onyx",
    )

    return parser.parse_args()

def set_up_logger(stdout_file):
    """Creates logger for component - all logging messages go to stdout
    log file, error messages also go to stderr log. If component runs
    correctly, stderr is empty.
    """
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s")

    out_handler = logging.FileHandler(stdout_file, mode="a")
    out_handler.setFormatter(formatter)
    logger.addHandler(out_handler)

    return logger


def create_analysis_fields(
    record_id: str,
    thresholds: dict, # Optional, GPHA required?
    results: dict, # Optional, needs to be a dictionary
    server: str,
    headline_result: str, # Required
    result_file: os.path,
) -> dict:
    """Set up fields dictionary used to populate analysis table containing
    AMR Pipeline Outputs.
    Arguments:
        record_id -- Climb ID for sample
        amr_pipeline_status -- Status of AMR pipeline analysis
        amr_annotations -- AMR annotations tsv file, if present
        server -- Server code is running on, one of "mscape" or "synthscape"
    Returns:
        onyx_analysis -- Class containing required fields for input to onyx
                         analysis table
    """
    onyx_analysis = oa.OnyxAnalysis()
    onyx_analysis.add_analysis_details(
        analysis_name="ukhsa-classifier-qc-metrics",
        analysis_description="This is an analysis to generate AMR results for individual samples",
    )
    # onyx_analysis.add_package_metadata(package_name="mscape-sample-qc")
    #TODO: read this from argsparse
    onyx_analysis.pipeline_name = "gpha-mscape-nf-amr"
    onyx_analysis.pipeline_version = 0.1
    onyx_analysis.pipeline_url = "https://github.com/ukhsa-collaboration/gpha-mscape-nf-amr"
    
    methods_fail = onyx_analysis.add_methods(methods_dict=thresholds)
    results_fail = onyx_analysis.add_results(top_result=headline_result, results_dict=results)
    onyx_analysis.add_server_records(sample_id=record_id, server_name=server)
    output_fail = onyx_analysis.add_output_location(result_file)
    required_field_fail, attribute_fail = onyx_analysis.check_analysis_object()

    if any([methods_fail, results_fail, output_fail, required_field_fail, attribute_fail]):
        exitcode = 1
    else:
        exitcode = 0

    return onyx_analysis, exitcode

def main():
    "Main function to process a given sample through QC."
    args = get_args()

    # Set up log file#
    log_file = Path(args.output) / f"{args.input}_amr_upload_log.txt"
    set_up_logger(log_file)
    
    #TODO: How to prep files for S3 location?
    if args.pipeline_status == str('Annotated'): # include tsv file
        results_file = args.tsv
    else:
        results_file = str('')
    
    onyx_analysis, exitcode = create_analysis_fields(
        args.input, # record_id
        {'pct_id': 90}, # Thresholds #TODO: pull this from nextflow..
        {'Number of Genes Annotated': ''}, # results #TODO: parse this from nextflow outputs 
        str(args.server), # server
        str(args.pipeline_status), #headline_result
        results_file # result_file
    )

    if exitcode == 1:
        logging.error("Invalid attribute in analysis fields submitted, check logs for details")
        return exitcode

        # Add data to analysis table
    if args.store_onyx:
        onyx_json_file = Path(args.output) / f"{args.input}_amr_analysis_fields.json"
        result_file = onyx_analysis.write_analysis_to_json(result_file=onyx_json_file)
        logging.info("Onyx analysis fields written to file %s", result_file)
        exitcode = 0
        return exitcode
    
if __name__ == "__main__":
    sys.exit(main())