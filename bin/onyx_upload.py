#!/usr/bin/env python3

"""Script to upload data generated by gpha-mscape-nf-amr pipeline. Three possible outputs:
- AMR analysis was not performed on sample.
- No AMR annotations were found for sample.
- AMR annotations were found for sample.
"""

import argparse
import logging
import os
import sys
from pathlib import Path

from onyx_analysis_helper import onyx_analysis_helper_functions as oa


def get_args() -> argparse.Namespace:
    """Get command line arguments"""
    parser = argparse.ArgumentParser(
        prog="AMR pipeline info Onyx upload",
        description="""Wrapper used to process AMR pipeline outputs. 
        Results are returned in a json format.
        """,
    )
    parser.add_argument("--input", "-i", type=str, required=True, help="Sample ID")
    parser.add_argument("--results_folder", "-f", type=str, required=True, help="Path to AMR results folder.")
    parser.add_argument("--output", "-o", type=str, required=True, help="Folder to save logs to.")
    parser.add_argument(
        "--pipeline_status",
        type=str,
        choices=["Failed", "Annotated", "None"],
        required=True,
        help="Pipeline Status. Choices: 'Failed', 'Annotated', 'None'",
    )
    parser.add_argument(
        "--amr_params",
        type=str,
        required=True,
        help="String of comma separated abricate configs: database:value,min_id:value,min_cov:value.",
    )
    parser.add_argument(
        "--pipeline_info",
        type=str,
        required=True,
        help="String of comma separated pipeline_info: pipeline_name:value,pipeline_version:value,pipeline_url:value.",
    )
    parser.add_argument(
        "--server",
        "-s",
        type=str,
        required=True,
        choices=["mscape", "synthscape"],
        help="Specify server code is being run on",
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--no-onyx",
        required=False,
        action="store_true",
        help="Use this option to only write results to file",
    )
    group.add_argument(
        "--store-onyx",
        required=False,
        action="store_true",
        help="Use this option to store results as an onyx analysis object for later upload",
    )
    group.add_argument(
        "--test-onyx",
        required=False,
        action="store_true",
        help="Use this option to do a test upload and check for errors before attempting an upload to onyx",
    )
    group.add_argument(
        "--prod-onyx",
        required=False,
        action="store_true",
        help="Use this option to upload results to onyx",
    )

    return parser.parse_args()


def set_up_logger(stdout_file: str) -> logging.Logger:
    """Creates logger for component - all logging messages go to stdout
    log file, error messages also go to stderr log. If component runs
    correctly, stderr is empty.
    """
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s")

    out_handler = logging.FileHandler(stdout_file, mode="a")
    out_handler.setFormatter(formatter)
    logger.addHandler(out_handler)

    return logger


def create_analysis_fields(
    record_id: str,
    thresholds: dict,
    pipeline_info: dict,
    results: dict,  # Optional, needs to be a dictionary
    server: str,
    headline_result: str,  # Required
    result_folder: os.path,
) -> dict:
    """Set up fields dictionary used to populate analysis table containing
    AMR Pipeline Outputs.
    Arguments:
        record_id -- Climb ID for sample
        thresholds -- AMR parameters used

        amr_annotations -- AMR annotations tsv file, if present
        server -- Server code is running on, one of "mscape" or "synthscape"
    Returns:
        onyx_analysis -- Class containing required fields for input to onyx
                         analysis table
    """
    onyx_analysis = oa.OnyxAnalysis()
    onyx_analysis.add_analysis_details(
        analysis_name=pipeline_info["name"],
        analysis_description="This is an analysis to generate AMR results for individual samples",
    )
    # onyx_analysis.add_package_metadata(package_name="mscape-sample-qc")
    # TODO: read this from argsparse
    onyx_analysis.pipeline_name = pipeline_info["name"]
    onyx_analysis.pipeline_version = pipeline_info["version"]
    onyx_analysis.pipeline_url = pipeline_info["homePage"]

    methods_fail = onyx_analysis.add_methods(methods_dict=thresholds)
    results_fail = onyx_analysis.add_results(top_result=headline_result, results_dict=results)
    onyx_analysis.add_server_records(sample_id=record_id, server_name=server)
    output_fail = onyx_analysis.add_output_location(result_folder)
    required_field_fail, attribute_fail = onyx_analysis.check_analysis_object()

    exitcode = 1 if any([methods_fail, results_fail, output_fail, required_field_fail, attribute_fail]) else 0

    return onyx_analysis, exitcode


def main() -> None:
    "Main function to process a given sample through QC."
    args = get_args()

    # Set up log file#
    log_file = Path(args.output) / f"{args.input}_amr_upload_log.txt"
    logger = set_up_logger(log_file)

    # Parse Abricate parameters
    amr_params_list = args.amr_params.split(",")
    amr_dict = {
        amr_params_list[0].split(":")[0]: amr_params_list[0].split(":")[1],
        amr_params_list[1].split(":")[0]: amr_params_list[1].split(":")[1],
        amr_params_list[2].split(":")[0]: amr_params_list[2].split(":")[1],
        amr_params_list[3].split(":")[0]: amr_params_list[3].split(":")[1],
    }

    # Parse pipeline information
    pipeline_info_list = args.pipeline_info.split(",")
    pipeline_info_dict = {
        pipeline_info_list[0].split(":")[0]: pipeline_info_list[0].split(":")[1],  # Name
        pipeline_info_list[1].split(":")[0]: pipeline_info_list[1].split(":")[1],  # Version
        pipeline_info_list[2].split(":")[0]: ":".join(pipeline_info_list[2].split(":")[1:]),  # WebURL
    }

    onyx_analysis, exitcode = create_analysis_fields(
        args.input,  # record_id
        amr_dict,  # Thresholds
        pipeline_info_dict,  # pipleine info
        {"Number of Genes Annotated": ""},  # results #TODO: parse this from nextflow outputs
        str(args.server),  # server
        str(args.pipeline_status),  # headline_result
        args.results_folder,  # result_folder
    )

    if exitcode == 1:
        logger.error("Invalid attribute in analysis fields submitted, check logs for details")
        return exitcode

        # Add data to analysis table
    if args.store_onyx:
        onyx_json_file = Path(args.output) / f"{args.input}_amr_analysis_fields.json"
        result_file = onyx_analysis.write_analysis_to_json(result_file=onyx_json_file)
        logger.info("Onyx analysis fields written to file %s", result_file)
        exitcode = 0


if __name__ == "__main__":
    sys.exit(main())
